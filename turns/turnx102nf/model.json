{
    "type": "non-fiction",
    "models": {
        "1.0": "Maskito v0.3.0_HYBRID",
        "2.0": "Maskito v0.3.0b_HYBRID",
        "3.0": "Maskito v0.3.0_RAW",
        "4.0": "Maskito v0.3.0b_RAW"
    },
    "research_objectives": "<ol><b><li>How do the new models (3.0 and 3.0b) perform compared to the state of the art?</li><li>Are there any significant performance differences with respect to the generation cycles (hybrid and raw)?</li></b></ol>",
    "research_findings": "<ol> <li><u>On the comparison between the models with varying training data (3.0 and 3.0b)</u> <br/><b>HYBRID</b>: There are no statistically significant differences that could be found between these models. In the criteria action_coherence, exhaustive_information, grammar, content_similarity and overall_quality, more outliers could be found for the model trained with English and German texts (3.0b). <br/><b>RAW</b>: A somewhat significant difference can be observed for the criterion content_similarity. A closer look in the data pertaining to this criterion shows that while the minimum value for both models is equal (21.58), the 3.0b model with the raw generation cycle produced texts which had a higher overall mean with most of those texts rated between 100 and 70. More importantly, there is a significant difference in overall_quality between the 3.0 and 3.0b models <i>(p-value=0.0287)</i>. While a similar level of significance can be observed for readability, results for this criterion are to be interpreted critically as IRA has likewise been low for this criterion in this turn (as the case has been in previous turns).</li><br/> <li><u>On the comparison between the generation cycles (hybrid and raw)</u> <br/><b>3.0</b>: With the same model, the generation cycle with fact masking (hybrid) generated better results in almost all criteria, most notably in identical_information and content_similarity. Linguistic difference was better with the raw generation cycle, with a higher mean and midspread, although this difference was not found to be statistically significant. <br/><b>3.0b</b>: In contrast to the model trained only with German texts, 3.0b showed better results when generating <b>WITHOUT</b> the fact-masking cycle (raw). Concretely, with a raw generation cycle, 3.0b exhibited slightly elevated ratings for the criteria overall_quality, linguistic_difference and factual_correctness. None of these positive differences, however, were found to be statistically significant.</li><br/> <li><u>On the comparison between new models and the state of the art (0.1.4)</u> <br/> Of the models analyzed above, the model which was trained with English and German texts (3.0b) and used for generation without fact-masking (3.0b_raw) showed the best results in terms of overall_quality in comparison to the other models in the current turn. Albeit not being significant, the high overall_quality score achieved by <u>the aforementioned model tops the overall_quality score of the current state of the art</u>. Furthermore, a slightly significant increase can also be seen in the criterion grammar with the 3.0b model with a raw generation cycle.</li></li></ol>"
}